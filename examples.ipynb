{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Extracting different feature examples\n",
    "\n",
    "This sections outlines some code snippets for how you can extract some slightly different features\n",
    "The first shows how you \"resample\" the signal so that all of the signal fits into the same amount of timesteps\n",
    "by stretching or compressing them, kind of like how you can do this with an image as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Conv1D, MaxPool1D, Flatten\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from scipy.signal import resample  # New line\n",
    "from helpers import train_to_id5\n",
    "from helpers import load_dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Change this to set how many steps long you want your time-series to be\n",
    "input_length = 20000\n",
    "\n",
    "\n",
    "# A function to extract the values we need as input and output for the model training\n",
    "# Note: You can make changes here to look at different features\n",
    "def extract_features(signals, train_types):\n",
    "    model_input = []\n",
    "    model_target = []\n",
    "    \n",
    "    # Iterate over all signals and corresponding train types\n",
    "    for signal, train_type in zip(signals, train_types):\n",
    "                \n",
    "        # Assemble the signal one data point\n",
    "        signal = resample(signal, input_length)\n",
    "        input_vector = np.reshape(signal, (-1, 1))  # special case if you have only 1 time series\n",
    "    \n",
    "        # Convert train type to number\n",
    "        target = train_to_id5(train_type)\n",
    "        \n",
    "        # Add to dataset to be fed to a machine learning algorithm\n",
    "        model_input.append(input_vector)\n",
    "        model_target.append(target)\n",
    "    \n",
    "    # Convert to a more digestable format and return the data, also makes also signals equally long\n",
    "    model_input = sequence.pad_sequences(model_input, input_length)\n",
    "    model_target = np.array(model_target)\n",
    "    return model_input, model_target\n",
    "\n",
    "\n",
    "# Load the data\n",
    "training_x, training_y = load_dataset(dataset='training')\n",
    "validate_x, validate_y = load_dataset(dataset='validate')\n",
    "\n",
    "# Transform the data / extract features\n",
    "training_x, training_y = extract_features(training_x, training_y)\n",
    "validate_x, validate_y = extract_features(validate_x, validate_y)\n",
    "\n",
    "\n",
    "# Build a Convolutional Neural Network\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=16, kernel_size=5, padding='valid', input_shape=training_x.shape[1:]))\n",
    "model.add(MaxPool1D(2))\n",
    "model.add(Conv1D(filters=16, kernel_size=5, padding='valid'))\n",
    "model.add(MaxPool1D(2))\n",
    "model.add(Conv1D(filters=16, kernel_size=5, padding='valid'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=5, activation='softmax'))\n",
    "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# Fit a model to the data. Note less epochs are needed here\n",
    "logger = model.fit(training_x, training_y, epochs=50, batch_size=32, validation_data=[validate_x, validate_y])\n",
    "\n",
    "# Visualize the fitting process to learn about how the model likely is\n",
    "plt.title('Accuracy over epochs')\n",
    "plt.plot(logger.history['acc'])\n",
    "plt.plot(logger.history['val_acc'])\n",
    "plt.legend(['training accuracy', 'validation accuracy'])\n",
    "plt.xlabel('Epochs')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "This following snippet shows how you can extract a \"periodogram\" from the signal. This is a type of transformation which gives you information about what kind of frequencies are present in the vibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Conv1D, MaxPool1D, Flatten\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from scipy.signal import periodogram  # New line\n",
    "from helpers import train_to_id5\n",
    "from helpers import load_dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Change this to set how many steps long you want your time-series to be\n",
    "input_length = 20000\n",
    "\n",
    "\n",
    "# A function to extract the values we need as input and output for the model training\n",
    "# Note: You can make changes here to look at different features\n",
    "def extract_features(signals, train_types):\n",
    "    model_input = []\n",
    "    model_target = []\n",
    "    \n",
    "    # Needs to be done before iterating over the signals in this case\n",
    "    signals = sequence.pad_sequences(signals, input_length * 2)\n",
    "    \n",
    "    # Iterate over all signals and corresponding train types\n",
    "    for signal, train_type in zip(signals, train_types):\n",
    "                \n",
    "        # Assemble the signal one data point\n",
    "        signal = periodogram(signal)[1]\n",
    "        input_vector = np.reshape(signal, (-1, 1))  # special case if you have only 1 time series\n",
    "    \n",
    "        # Convert train type to number\n",
    "        target = train_to_id5(train_type)\n",
    "        \n",
    "        # Add to dataset to be fed to a machine learning algorithm\n",
    "        model_input.append(input_vector)\n",
    "        model_target.append(target)\n",
    "    \n",
    "    # Convert to a more digestable format and return the data, also makes also signals equally long\n",
    "    model_input = np.array(model_input)\n",
    "    model_target = np.array(model_target)\n",
    "    return model_input, model_target\n",
    "\n",
    "\n",
    "# Load the data\n",
    "training_x, training_y = load_dataset(dataset='training')\n",
    "validate_x, validate_y = load_dataset(dataset='validate')\n",
    "\n",
    "# Transform the data / extract features\n",
    "training_x, training_y = extract_features(training_x, training_y)\n",
    "validate_x, validate_y = extract_features(validate_x, validate_y)\n",
    "\n",
    "\n",
    "# Build a Convolutional Neural Network\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=16, kernel_size=5, padding='valid', input_shape=training_x.shape[1:]))\n",
    "model.add(MaxPool1D(2))\n",
    "model.add(Conv1D(filters=16, kernel_size=5, padding='valid'))\n",
    "model.add(MaxPool1D(2))\n",
    "model.add(Conv1D(filters=16, kernel_size=5, padding='valid'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=5, activation='softmax'))\n",
    "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# Fit a model to the data. Note less epochs are needed here\n",
    "logger = model.fit(training_x, training_y, epochs=50, batch_size=32, validation_data=[validate_x, validate_y])\n",
    "\n",
    "# Visualize the fitting process to learn about how the model likely is\n",
    "plt.title('Accuracy over epochs')\n",
    "plt.plot(logger.history['acc'])\n",
    "plt.plot(logger.history['val_acc'])\n",
    "plt.legend(['training accuracy', 'validation accuracy'])\n",
    "plt.xlabel('Epochs')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Changing the model target\n",
    "\n",
    "Until now, we have been setting \"unknown\" trains as it's own train type which we try to classify. We can however also try to only classify the 4 relevant types of trains and treating the absence of this as an \"unknown\" type.\n",
    "This can be achieved by using the helper function \"train_to_id4\" and changing a couple of things in the model, in particular we'll use \"binary_crossentropy\" instead of \"categorical_crossentropy\", which means we try to determine how likely it is that this signal is that particular train type, meaning it could theoretically possible for it to think that it could be 2 types of trains at the same time. This also changes the output of the validation accuracy a bit since it now check for accuracy over 4 outputs instead of one per sample, i.e. if 3 of the 4 output values say it is not this train type and the last one say it is this one, even if it got the train type wrong it would still be 50% correct (2 correct \"not this type\" and 1 incorrect \"not this type\" as well as 1 incorrect \"it is this type\"). Feel free to ask me for more details about this\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Conv1D, MaxPool1D, Flatten\n",
    "from keras.models import Sequential\n",
    "from helpers import train_to_id4\n",
    "from helpers import load_dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Change this to set how many steps long you want your time-series to be\n",
    "input_length = 20000\n",
    "\n",
    "\n",
    "# A function to extract the values we need as input and output for the model training\n",
    "# Note: You can make changes here to look at different features\n",
    "def extract_features(signals, train_types):\n",
    "    model_input = []\n",
    "    model_target = []\n",
    "    \n",
    "    # Iterate over all signals and corresponding train types\n",
    "    for signal, train_type in zip(signals, train_types):\n",
    "                \n",
    "        # Assemble the signal one data point\n",
    "        input_vector = np.reshape(signal, (-1, 1))  # special case if you have only 1 time series\n",
    "    \n",
    "        # Convert train type to number\n",
    "        target = train_to_id4(train_type)\n",
    "        \n",
    "        # Add to dataset to be fed to a machine learning algorithm\n",
    "        model_input.append(input_vector)\n",
    "        model_target.append(target)\n",
    "    \n",
    "    # Convert to a more digestable format and return the data, also makes also signals equally long\n",
    "    model_input = np.array(model_input)\n",
    "    model_target = np.array(model_target)\n",
    "    return model_input, model_target\n",
    "\n",
    "\n",
    "# Load the data\n",
    "training_x, training_y = load_dataset(dataset='training')\n",
    "validate_x, validate_y = load_dataset(dataset='validate')\n",
    "\n",
    "# Transform the data / extract features\n",
    "training_x, training_y = extract_features(training_x, training_y)\n",
    "validate_x, validate_y = extract_features(validate_x, validate_y)\n",
    "\n",
    "\n",
    "# Build a Convolutional Neural Network\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=16, kernel_size=5, padding='valid', input_shape=training_x.shape[1:]))\n",
    "model.add(MaxPool1D(2))\n",
    "model.add(Conv1D(filters=16, kernel_size=5, padding='valid'))\n",
    "model.add(MaxPool1D(2))\n",
    "model.add(Conv1D(filters=16, kernel_size=5, padding='valid'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=4, activation='sigmoid'))  # softmax does not work well with binary_crossentropy\n",
    "model.compile(optimizer='sgd', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# Fit a model to the data. Note less epochs are needed here\n",
    "logger = model.fit(training_x, training_y, epochs=50, batch_size=32, validation_data=[validate_x, validate_y])\n",
    "\n",
    "# Visualize the fitting process to learn about how the model likely is\n",
    "plt.title('Accuracy over epochs')\n",
    "plt.plot(logger.history['acc'])\n",
    "plt.plot(logger.history['val_acc'])\n",
    "plt.legend(['training accuracy', 'validation accuracy'])\n",
    "plt.xlabel('Epochs')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
